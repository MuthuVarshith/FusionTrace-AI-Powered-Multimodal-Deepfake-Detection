{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mv: cannot stat '.kaggle/kaggle.json': No such file or directory\n",
      "chmod: cannot access '/teamspace/studios/this_studio/.kaggle/kaggle.json': No such file or directory\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p ~/.kaggle\n",
    "!mv .kaggle/kaggle.json ~/.kaggle/\n",
    "!chmod 600 ~/.kaggle/kaggle.json\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: tree\n"
     ]
    }
   ],
   "source": [
    "!tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /teamspace/studios/this_studio/.kaggle/kaggle.json'\n",
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /teamspace/studios/this_studio/.kaggle/kaggle.json'\n",
      "Authenticated successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Make a directory if it doesn't exist\n",
    "os.makedirs(\".kaggle\", exist_ok=True)\n",
    "\n",
    "# Move and rename the file\n",
    "shutil.move(\".kaggle.json\", \".kaggle/kaggle.json\")\n",
    "\n",
    "# Set environment variable\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = os.path.abspath('.kaggle')\n",
    "\n",
    "# Authenticate\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "\n",
    "print(\"Authenticated successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚¨áÔ∏è Downloading dataset via CLI (faster)...\n",
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /teamspace/studios/this_studio/.kaggle/kaggle.json'\n",
      "Dataset URL: https://www.kaggle.com/datasets/alaaeddineayadi/real-vs-ai-generated-faces\n",
      "License(s): apache-2.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Download complete.\n",
      "üì¶ Unzipping files...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 12188/12188 [00:38<00:00, 317.84file/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Dataset ready at: ./datasets/real_vs_ai_faces\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "from tqdm import tqdm\n",
    "import zipfile\n",
    "\n",
    "# Set Kaggle credentials\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = os.path.abspath('.kaggle')\n",
    "\n",
    "# Define paths\n",
    "dataset = \"alaaeddineayadi/real-vs-ai-generated-faces\"\n",
    "download_path = \"./datasets/real_vs_ai_faces\"\n",
    "zip_path = os.path.join(download_path, \"real-vs-ai-generated-faces.zip\")\n",
    "\n",
    "# Create directory\n",
    "os.makedirs(download_path, exist_ok=True)\n",
    "\n",
    "# Download using CLI via subprocess\n",
    "print(\"‚¨áÔ∏è Downloading dataset via CLI (faster)...\")\n",
    "subprocess.run(\n",
    "    [\"kaggle\", \"datasets\", \"download\", \"-d\", dataset, \"-p\", download_path],\n",
    "    check=True\n",
    ")\n",
    "print(\"‚úÖ Download complete.\")\n",
    "\n",
    "# Unzip with progress\n",
    "print(\"üì¶ Unzipping files...\")\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    total_files = len(zip_ref.infolist())\n",
    "    for file in tqdm(zip_ref.infolist(), desc=\"Extracting\", unit=\"file\", total=total_files):\n",
    "        zip_ref.extract(file, path=download_path)\n",
    "\n",
    "# Delete the zip\n",
    "os.remove(zip_path)\n",
    "\n",
    "print(\"‚úÖ Dataset ready at:\", download_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚¨áÔ∏è Downloading: xhlulu/140k-real-and-fake-faces\n",
      "Warning: Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /teamspace/studios/this_studio/.kaggle/kaggle.json'\n",
      "Dataset URL: https://www.kaggle.com/datasets/xhlulu/140k-real-and-fake-faces\n",
      "License(s): other\n",
      "‚úÖ Download completed: 140k-real-and-fake-faces.zip\n",
      "üì¶ Extracting contents...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting to 140k_faces:  17%|‚ñà‚ñã        | 24088/140003 [00:04<00:20, 5539.18file/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting to 140k_faces: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 140003/140003 [00:25<00:00, 5491.05file/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Finished: Dataset extracted to 'datasets/140k_faces'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import zipfile\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set Kaggle config path\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = os.path.abspath('.kaggle')\n",
    "\n",
    "# Dataset details\n",
    "dataset_id = \"xhlulu/140k-real-and-fake-faces\"\n",
    "folder_name = \"140k_faces\"\n",
    "download_path = os.path.join(\"datasets\", folder_name)\n",
    "zip_filename = dataset_id.split('/')[-1] + \".zip\"\n",
    "zip_path = os.path.join(download_path, zip_filename)\n",
    "\n",
    "# Create target directory\n",
    "os.makedirs(download_path, exist_ok=True)\n",
    "\n",
    "# Download using kaggle CLI\n",
    "print(f\"\\n‚¨áÔ∏è Downloading: {dataset_id}\")\n",
    "subprocess.run(\n",
    "    [\"kaggle\", \"datasets\", \"download\", \"-d\", dataset_id, \"-p\", download_path],\n",
    "    check=True\n",
    ")\n",
    "print(\"‚úÖ Download completed:\", zip_filename)\n",
    "\n",
    "# Extract with tqdm progress\n",
    "print(\"üì¶ Extracting contents...\")\n",
    "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
    "    total_files = len(zip_ref.infolist())\n",
    "    for file in tqdm(zip_ref.infolist(), desc=f\"Extracting to {folder_name}\", unit=\"file\", total=total_files):\n",
    "        zip_ref.extract(file, path=download_path)\n",
    "\n",
    "# Remove zip after extraction\n",
    "os.remove(zip_path)\n",
    "print(f\"‚úÖ Finished: Dataset extracted to '{download_path}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ Folder structure of 'real_vs_ai_faces':\n",
      "‚îî‚îÄ‚îÄ dataset\n",
      "    ‚îú‚îÄ‚îÄ val\n",
      "    ‚îÇ   ‚îú‚îÄ‚îÄ fake\n",
      "    ‚îÇ   ‚îî‚îÄ‚îÄ real\n",
      "    ‚îú‚îÄ‚îÄ train\n",
      "    ‚îÇ   ‚îú‚îÄ‚îÄ fake\n",
      "    ‚îÇ   ‚îî‚îÄ‚îÄ real\n",
      "    ‚îî‚îÄ‚îÄ test\n",
      "        ‚îú‚îÄ‚îÄ fake\n",
      "        ‚îî‚îÄ‚îÄ real\n",
      "\n",
      "üìÅ Folder structure of '140k_faces':\n",
      "‚îî‚îÄ‚îÄ real_vs_fake\n",
      "    ‚îî‚îÄ‚îÄ real-vs-fake\n",
      "        ‚îú‚îÄ‚îÄ train\n",
      "        ‚îÇ   ‚îú‚îÄ‚îÄ fake\n",
      "        ‚îÇ   ‚îî‚îÄ‚îÄ real\n",
      "        ‚îú‚îÄ‚îÄ test\n",
      "        ‚îÇ   ‚îú‚îÄ‚îÄ fake\n",
      "        ‚îÇ   ‚îî‚îÄ‚îÄ real\n",
      "        ‚îî‚îÄ‚îÄ valid\n",
      "            ‚îú‚îÄ‚îÄ fake\n",
      "            ‚îî‚îÄ‚îÄ real\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def print_folder_tree(start_path, prefix=\"\"):\n",
    "    items = [item for item in os.listdir(start_path) if os.path.isdir(os.path.join(start_path, item))]\n",
    "    pointers = ['‚îú‚îÄ‚îÄ '] * (len(items) - 1) + ['‚îî‚îÄ‚îÄ ']\n",
    "\n",
    "    for pointer, item in zip(pointers, items):\n",
    "        path = os.path.join(start_path, item)\n",
    "        print(prefix + pointer + item)\n",
    "        extension = '‚îÇ   ' if pointer == '‚îú‚îÄ‚îÄ ' else '    '\n",
    "        print_folder_tree(path, prefix + extension)\n",
    "\n",
    "# üîç Replace with your actual dataset paths\n",
    "print(\"üìÅ Folder structure of 'real_vs_ai_faces':\")\n",
    "print_folder_tree('datasets/real_vs_ai_faces')\n",
    "\n",
    "print(\"\\nüìÅ Folder structure of '140k_faces':\")\n",
    "print_folder_tree('datasets/140k_faces')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying real from real:   3%|‚ñé         | 324/10000 [00:00<00:03, 3161.58img/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying real from real: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10000/10000 [00:02<00:00, 3806.39img/s]\n",
      "Copying real from fake: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 10000/10000 [00:02<00:00, 3379.31img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ All images successfully combined into 'data/real' and 'data/fake'.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Output folders\n",
    "output_real_dir = 'data/real'\n",
    "output_fake_dir = 'data/fake'\n",
    "os.makedirs(output_real_dir, exist_ok=True)\n",
    "os.makedirs(output_fake_dir, exist_ok=True)\n",
    "\n",
    "# All source directories from both datasets\n",
    "input_dirs = [\n",
    "    # real_vs_fake (140k_faces)\n",
    "    # 'datasets/140k_faces/real_vs_fake/real-vs-fake/train/real',\n",
    "    'datasets/140k_faces/real_vs_fake/real-vs-fake/valid/real',\n",
    "    # 'datasets/140k_faces/real_vs_fake/real-vs-fake/test/real',\n",
    "    # 'datasets/140k_faces/real_vs_fake/real-vs-fake/train/fake',\n",
    "    'datasets/140k_faces/real_vs_fake/real-vs-fake/valid/fake',\n",
    "    # 'datasets/140k_faces/real_vs_fake/real-vs-fake/test/fake',\n",
    "\n",
    "    # real_vs_ai_faces\n",
    "    # 'datasets/real_vs_ai_faces/dataset/train/real',\n",
    "    # 'datasets/real_vs_ai_faces/dataset/val/real',\n",
    "    # 'datasets/real_vs_ai_faces/dataset/test/real',\n",
    "    # 'datasets/real_vs_ai_faces/dataset/train/fake',\n",
    "    # 'datasets/real_vs_ai_faces/dataset/val/fake',\n",
    "    # 'datasets/real_vs_ai_faces/dataset/test/fake',\n",
    "]\n",
    "\n",
    "# Copy function with filename collision check\n",
    "def copy_file(src_path, dst_folder):\n",
    "    filename = os.path.basename(src_path)\n",
    "    dst_path = os.path.join(dst_folder, filename)\n",
    "\n",
    "    base, ext = os.path.splitext(filename)\n",
    "    counter = 1\n",
    "    while os.path.exists(dst_path):\n",
    "        dst_path = os.path.join(dst_folder, f\"{base}_{counter}{ext}\")\n",
    "        counter += 1\n",
    "\n",
    "    shutil.copy2(src_path, dst_path)\n",
    "\n",
    "# Main processing\n",
    "def process_folder(folder, class_type):\n",
    "    if not os.path.exists(folder):\n",
    "        print(f\"‚ùå Folder not found: {folder}\")\n",
    "        return\n",
    "\n",
    "    dst_folder = output_real_dir if class_type == 'real' else output_fake_dir\n",
    "    images = [os.path.join(folder, f) for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]\n",
    "\n",
    "    with ThreadPoolExecutor() as executor:\n",
    "        list(tqdm(executor.map(lambda img: copy_file(img, dst_folder), images),\n",
    "                  total=len(images),\n",
    "                  desc=f'Copying {class_type} from {os.path.basename(folder)}',\n",
    "                  unit='img'))\n",
    "\n",
    "# Process all folders\n",
    "for folder in input_dirs:\n",
    "    if 'real' in folder:\n",
    "        process_folder(folder, 'real')\n",
    "    elif 'fake' in folder:\n",
    "        process_folder(folder, 'fake')\n",
    "\n",
    "print(\"\\n‚úÖ All images successfully combined into 'data/real' and 'data/fake'.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Dataset 1: real-vs-fake\n",
    "dataset1_real = [\n",
    "    'datasets/real_vs_fake/real-vs-fake/train/real',\n",
    "    'datasets/real_vs_fake/real-vs-fake/valid/real',\n",
    "    'datasets/real_vs_fake/real-vs-fake/test/real'\n",
    "]\n",
    "dataset1_fake = [\n",
    "    'datasets/real_vs_fake/real-vs-fake/train/fake',\n",
    "    'datasets/real_vs_fake/real-vs-fake/valid/fake',\n",
    "    'datasets/real_vs_fake/real-vs-fake/test/fake'\n",
    "]\n",
    "\n",
    "# Dataset 2: real_vs_ai_faces\n",
    "dataset2_real = [\n",
    "    'datasets/real_vs_ai_faces/dataset/train/real',\n",
    "    'datasets/real_vs_ai_faces/dataset/val/real',\n",
    "    'datasets/real_vs_ai_faces/dataset/test/real'\n",
    "]\n",
    "dataset2_fake = [\n",
    "    'datasets/real_vs_ai_faces/dataset/train/fake',\n",
    "    'datasets/real_vs_ai_faces/dataset/val/fake',\n",
    "    'datasets/real_vs_ai_faces/dataset/test/fake'\n",
    "]\n",
    "\n",
    "# Output folders\n",
    "output_real = 'data/real'\n",
    "output_fake = 'data/fake'\n",
    "os.makedirs(output_real, exist_ok=True)\n",
    "os.makedirs(output_fake, exist_ok=True)\n",
    "\n",
    "# Function to copy all images from given folders\n",
    "def copy_from_folders(folders, dest_folder, prefix):\n",
    "    img_count = 0\n",
    "    for folder in folders:\n",
    "        label = os.path.basename(folder)  # real/fake\n",
    "        split = folder.split('/')[-2]     # train/val/test\n",
    "        files = [f for f in os.listdir(folder) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "        for file in tqdm(files, desc=f\"üìÅ Copying {label} from {split}\", unit='img'):\n",
    "            src = os.path.join(folder, file)\n",
    "            new_name = f\"{prefix}_{split}_{img_count}_{file}\"\n",
    "            dst = os.path.join(dest_folder, new_name)\n",
    "            shutil.copy2(src, dst)\n",
    "            img_count += 1\n",
    "    print(f\"‚úÖ Copied {img_count} images to {dest_folder}\\n\")\n",
    "\n",
    "# Copy from all sources\n",
    "copy_from_folders(dataset1_real, output_real, prefix='d1')\n",
    "copy_from_folders(dataset1_fake, output_fake, prefix='d1')\n",
    "\n",
    "copy_from_folders(dataset2_real, output_real, prefix='d2')\n",
    "copy_from_folders(dataset2_fake, output_fake, prefix='d2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Copying REAL from datasets/real_vs_ai_faces/dataset/train/real: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 5750/5750 [02:10<00:00, 44.20img/s] \n",
      "Copying REAL from datasets/real_vs_ai_faces/dataset/val/real: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 718/718 [00:00<00:00, 4263.86img/s]\n",
      "Copying REAL from datasets/real_vs_ai_faces/dataset/test/real: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 720/720 [00:01<00:00, 403.76img/s]\n",
      "Copying FAKE from datasets/real_vs_ai_faces/dataset/train/fake: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 4000/4000 [00:03<00:00, 1060.19img/s]\n",
      "Copying FAKE from datasets/real_vs_ai_faces/dataset/val/fake: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:03<00:00, 133.25img/s]\n",
      "Copying FAKE from datasets/real_vs_ai_faces/dataset/test/fake: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 500/500 [00:03<00:00, 138.06img/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ All images successfully copied to data/real and data/fake.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Final output folders\n",
    "target_real = 'data/real'\n",
    "target_fake = 'data/fake'\n",
    "\n",
    "# Ensure output directories exist\n",
    "os.makedirs(target_real, exist_ok=True)\n",
    "os.makedirs(target_fake, exist_ok=True)\n",
    "\n",
    "# Dataset 1 paths\n",
    "dataset1_real = [\n",
    "    'datasets/real_vs_fake/real-vs-fake/train/real',\n",
    "    'datasets/real_vs_fake/real-vs-fake/valid/real',\n",
    "    'datasets/real_vs_fake/real-vs-fake/test/real'\n",
    "]\n",
    "dataset1_fake = [\n",
    "    'datasets/real_vs_fake/real-vs-fake/train/fake',\n",
    "    'datasets/real_vs_fake/real-vs-fake/valid/fake',\n",
    "    'datasets/real_vs_fake/real-vs-fake/test/fake'\n",
    "]\n",
    "\n",
    "# Dataset 2 paths (with 'val')\n",
    "dataset2_real = [\n",
    "    'datasets/real_vs_ai_faces/dataset/train/real',\n",
    "    'datasets/real_vs_ai_faces/dataset/val/real',\n",
    "    'datasets/real_vs_ai_faces/dataset/test/real'\n",
    "]\n",
    "dataset2_fake = [\n",
    "    'datasets/real_vs_ai_faces/dataset/train/fake',\n",
    "    'datasets/real_vs_ai_faces/dataset/val/fake',\n",
    "    'datasets/real_vs_ai_faces/dataset/test/fake'\n",
    "]\n",
    "\n",
    "# Combine all paths\n",
    "all_real_dirs = dataset1_real + dataset2_real\n",
    "all_fake_dirs = dataset1_fake + dataset2_fake\n",
    "\n",
    "# Function to copy files with progress bar\n",
    "def copy_images(src_dirs, dest_dir, label):\n",
    "    for folder in src_dirs:\n",
    "        if os.path.exists(folder):\n",
    "            images = [f for f in os.listdir(folder) if os.path.isfile(os.path.join(folder, f))]\n",
    "            for img in tqdm(images, desc=f\"Copying {label} from {folder}\", unit=\"img\"):\n",
    "                src_path = os.path.join(folder, img)\n",
    "                dst_path = os.path.join(dest_dir, img)\n",
    "                shutil.copy2(src_path, dst_path)\n",
    "\n",
    "# ‚úÖ Copy all images\n",
    "copy_images(all_real_dirs, target_real, \"REAL\")\n",
    "copy_images(all_fake_dirs, target_fake, \"FAKE\")\n",
    "\n",
    "print(\"\\n‚úÖ All images successfully copied to data/real and data/fake.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ data/real: 7188 files, 1.83 GB (1871.71 MB)\n",
      "üìÅ data/fake: 5000 files, 6.16 GB (6302.88 MB)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def count_files_and_size(folder):\n",
    "    total_size = 0\n",
    "    total_files = 0\n",
    "    for root, _, files in os.walk(folder):\n",
    "        total_files += len(files)\n",
    "        for f in files:\n",
    "            fp = os.path.join(root, f)\n",
    "            if os.path.isfile(fp):\n",
    "                total_size += os.path.getsize(fp)\n",
    "    size_mb = total_size / (1024 * 1024)\n",
    "    size_gb = total_size / (1024 * 1024 * 1024)\n",
    "    return total_files, size_mb, size_gb\n",
    "\n",
    "# Folder paths\n",
    "real_path = 'data/real'\n",
    "fake_path = 'data/fake'\n",
    "\n",
    "# Count files and sizes\n",
    "real_files, real_mb, real_gb = count_files_and_size(real_path)\n",
    "fake_files, fake_mb, fake_gb = count_files_and_size(fake_path)\n",
    "\n",
    "# Display results\n",
    "print(f\"üìÅ data/real: {real_files} files, {real_gb:.2f} GB ({real_mb:.2f} MB)\")\n",
    "print(f\"üìÅ data/fake: {fake_files} files, {fake_gb:.2f} GB ({fake_mb:.2f} MB)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Moving extras from data/real to extra/real: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2188/2188 [00:00<00:00, 26855.80file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Moved 2188 files to extra/real\n",
      "‚úÖ No extra files to move from data/fake. Total: 5000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "from tqdm import tqdm\n",
    "\n",
    "def move_extras(src_folder, max_keep, dest_folder):\n",
    "    os.makedirs(dest_folder, exist_ok=True)\n",
    "    files = [f for f in os.listdir(src_folder) if os.path.isfile(os.path.join(src_folder, f))]\n",
    "    \n",
    "    if len(files) <= max_keep:\n",
    "        print(f\"‚úÖ No extra files to move from {src_folder}. Total: {len(files)}\")\n",
    "        return\n",
    "\n",
    "    extra_files = random.sample(files, len(files) - max_keep)\n",
    "\n",
    "    for f in tqdm(extra_files, desc=f\"Moving extras from {src_folder} to {dest_folder}\", unit=\"file\"):\n",
    "        src_path = os.path.join(src_folder, f)\n",
    "        dest_path = os.path.join(dest_folder, f)\n",
    "        shutil.move(src_path, dest_path)\n",
    "\n",
    "    print(f\"‚úÖ Moved {len(extra_files)} files to {dest_folder}\")\n",
    "\n",
    "# Move extra files\n",
    "move_extras(\"data/real\", max_keep=5000, dest_folder=\"extra/real\")\n",
    "move_extras(\"data/fake\", max_keep=5000, dest_folder=\"extra/fake\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìÅ data/real: 5000 files, 1.29 GB (1319.19 MB)\n",
      "üìÅ data/fake: 5000 files, 6.16 GB (6302.88 MB)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def count_files_and_size(folder):\n",
    "    total_size = 0\n",
    "    total_files = 0\n",
    "    for root, _, files in os.walk(folder):\n",
    "        total_files += len(files)\n",
    "        for f in files:\n",
    "            fp = os.path.join(root, f)\n",
    "            if os.path.isfile(fp):\n",
    "                total_size += os.path.getsize(fp)\n",
    "    size_mb = total_size / (1024 * 1024)\n",
    "    size_gb = total_size / (1024 * 1024 * 1024)\n",
    "    return total_files, size_mb, size_gb\n",
    "\n",
    "# Folder paths\n",
    "real_path = 'data/real'\n",
    "fake_path = 'data/fake'\n",
    "\n",
    "# Count files and sizes\n",
    "real_files, real_mb, real_gb = count_files_and_size(real_path)\n",
    "fake_files, fake_mb, fake_gb = count_files_and_size(fake_path)\n",
    "\n",
    "# Display results\n",
    "print(f\"üìÅ data/real: {real_files} files, {real_gb:.2f} GB ({real_mb:.2f} MB)\")\n",
    "print(f\"üìÅ data/fake: {fake_files} files, {fake_gb:.2f} GB ({fake_mb:.2f} MB)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
